{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">به نام خدا</div></center>\n",
    "<h1><center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">مقدمه ای بر شبکه‌های عصبی کانولوشنالی<br>Convolutionl Neural Networks - CNN</div></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">مقدمه ای بر شبکه‌های عصبی کانولوشنالی(Convolutionl Neural Networks - CNN)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "در ابتدا معماری شبکه را مشخص میکنیم.\n",
    "<br>\n",
    "به لایه های conv و pool دقت کنید.\n",
    "<br>\n",
    "قبل از اولین لایه Dense یا Fully Connected همیشه متد Flatten فراخوانی میشود تا نورون ها به صورت یک وکتور در بیایند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">اجرا روی Colab</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "اگر روی گوگل کولب اجرا میکنید این خطوط را از حالت کامنت خارج نمائید.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset.py\n",
    "#!mkdir dataset\n",
    "#!wget https://github.com/Alireza-Akhavan/SRU-deeplearning-workshop/raw/master/dataset/Data_hoda_full.mat -P dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import numpy as np\n",
    "from dataset import load_hoda\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "نگاهی به تنسور وردی و خروجی هر لایه بیندازیم.\n",
    "<br>\n",
    "تصویر ورودی 28x28x3 بوده است\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                36928     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">کد یک شبکه کانولوشنالی و آموزش آن از ابتدا تا انتها بر روی مجموعه داده هدی</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "تصاویر مجموعه داده هدی در تابعی که قبلا نوشته ایم، load_hoda به صورت flat شده و یک وکتور در آمده اند.\n",
    "<br>\n",
    "در این فراخوانی طول و عرض تصاویر 28 قرار داده شده است، پس خروجی این تابع وکتورهای 784تایی است.\n",
    "<br>\n",
    "** دقت کنید که قبل از ورودی شبکه کانولوشنالی تصویر را به شکل اصلی خود یعنی 28x28 برگردانده ایم.**\n",
    "<br>\n",
    "همچنین چون تصاویر سیاه و سفید است تعداد کانال تصویر را 1 قرار داده ایم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0220 - accuracy: 0.3451 - val_loss: 1.3143 - val_accuracy: 0.6900 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 1.1955 - accuracy: 0.5997 - val_loss: 0.5598 - val_accuracy: 0.8350 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.7771 - accuracy: 0.7403 - val_loss: 0.3688 - val_accuracy: 0.8900 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.5958 - accuracy: 0.8040 - val_loss: 0.2825 - val_accuracy: 0.9050 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.4786 - accuracy: 0.8497 - val_loss: 0.2137 - val_accuracy: 0.9250 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.3995 - accuracy: 0.8686 - val_loss: 0.1977 - val_accuracy: 0.9350 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.3306 - accuracy: 0.8937 - val_loss: 0.1604 - val_accuracy: 0.9450 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.2869 - accuracy: 0.9066 - val_loss: 0.1450 - val_accuracy: 0.9550 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.2554 - accuracy: 0.9163 - val_loss: 0.1371 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.2267 - accuracy: 0.9234 - val_loss: 0.1238 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.2289 - accuracy: 0.9297 - val_loss: 0.1127 - val_accuracy: 0.9650 - lr: 0.0010\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1882 - accuracy: 0.9397 - val_loss: 0.1132 - val_accuracy: 0.9600 - lr: 0.0010\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1734 - accuracy: 0.9429 - val_loss: 0.1006 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1517 - accuracy: 0.9511 - val_loss: 0.0867 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.1566 - accuracy: 0.9500 - val_loss: 0.0975 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1343 - accuracy: 0.9569 - val_loss: 0.0951 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.1321 - accuracy: 0.9540 - val_loss: 0.0976 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.1172 - accuracy: 0.9637 - val_loss: 0.0889 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1209 - accuracy: 0.9594 - val_loss: 0.0834 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1019 - accuracy: 0.9631 - val_loss: 0.0937 - val_accuracy: 0.9650 - lr: 0.0010\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0966 - accuracy: 0.9666 - val_loss: 0.0729 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1034 - accuracy: 0.9677 - val_loss: 0.1008 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0855 - accuracy: 0.9714 - val_loss: 0.0723 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0816 - accuracy: 0.9726 - val_loss: 0.0845 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0766 - accuracy: 0.9769 - val_loss: 0.0826 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0882 - accuracy: 0.9666 - val_loss: 0.0770 - val_accuracy: 0.9650 - lr: 0.0010\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0890 - accuracy: 0.9714 - val_loss: 0.0799 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0820 - accuracy: 0.9749 - val_loss: 0.0743 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0668 - accuracy: 0.9766 - val_loss: 0.1025 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0612 - accuracy: 0.9791 - val_loss: 0.0769 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0635 - accuracy: 0.9791 - val_loss: 0.0893 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0599 - accuracy: 0.9783 - val_loss: 0.0856 - val_accuracy: 0.9650 - lr: 0.0010\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: 0.0838 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0597 - accuracy: 0.9789 - val_loss: 0.0682 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0577 - accuracy: 0.9786 - val_loss: 0.0739 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0502 - accuracy: 0.9851 - val_loss: 0.0692 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0546 - accuracy: 0.9814 - val_loss: 0.0570 - val_accuracy: 0.9800 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0417 - accuracy: 0.9871 - val_loss: 0.0710 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0464 - accuracy: 0.9840 - val_loss: 0.0627 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0437 - accuracy: 0.9837 - val_loss: 0.0808 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0473 - accuracy: 0.9846 - val_loss: 0.0944 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0400 - accuracy: 0.9874 - val_loss: 0.0662 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0305 - accuracy: 0.9891 - val_loss: 0.0694 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0409 - accuracy: 0.9854 - val_loss: 0.0864 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0366 - accuracy: 0.9869 - val_loss: 0.0766 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0333 - accuracy: 0.9869 - val_loss: 0.0717 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0493 - accuracy: 0.9811 - val_loss: 0.0821 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0374 - accuracy: 0.9854 - val_loss: 0.0735 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0274 - accuracy: 0.9909 - val_loss: 0.0822 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0285 - accuracy: 0.9900 - val_loss: 0.0784 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0345 - accuracy: 0.9877 - val_loss: 0.1060 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0274 - accuracy: 0.9900 - val_loss: 0.0908 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0320 - accuracy: 0.9891 - val_loss: 0.0779 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0300 - accuracy: 0.9900 - val_loss: 0.1114 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.0771 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0289 - accuracy: 0.9906 - val_loss: 0.1095 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0289 - accuracy: 0.9889 - val_loss: 0.0905 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0272 - accuracy: 0.9897 - val_loss: 0.1184 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0283 - accuracy: 0.9900 - val_loss: 0.0717 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0237 - accuracy: 0.9929 - val_loss: 0.1294 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.0930 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0227 - accuracy: 0.9920 - val_loss: 0.1085 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0260 - accuracy: 0.9906 - val_loss: 0.1344 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0254 - accuracy: 0.9911 - val_loss: 0.0921 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.1376 - val_accuracy: 0.9600 - lr: 0.0010\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0243 - accuracy: 0.9909 - val_loss: 0.1092 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.1494 - val_accuracy: 0.9600 - lr: 0.0010\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0294 - accuracy: 0.9897 - val_loss: 0.0933 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.0830 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.0964 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0218 - accuracy: 0.9911 - val_loss: 0.1240 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.0936 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 0.1220 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.1044 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.1133 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0202 - accuracy: 0.9929 - val_loss: 0.1232 - val_accuracy: 0.9650 - lr: 0.0010\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.1065 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0205 - accuracy: 0.9923 - val_loss: 0.1097 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.0700 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.1081 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.0990 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0977 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0140 - accuracy: 0.9943 - val_loss: 0.1315 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.1724 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.1103 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.1082 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0174 - accuracy: 0.9931 - val_loss: 0.0929 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.1030 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0175 - accuracy: 0.9931 - val_loss: 0.1024 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 0.1235 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.1281 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.1365 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0101 - accuracy: 0.9957 - val_loss: 0.1289 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.1531 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 0.1604 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.1612 - val_accuracy: 0.9650 - lr: 0.0010\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0101 - accuracy: 0.9957 - val_loss: 0.1468 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.1681 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0156 - accuracy: 0.9943 - val_loss: 0.1703 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0165 - accuracy: 0.9937 - val_loss: 0.1183 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.1201 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.1033 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.1065 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0163 - accuracy: 0.9960 - val_loss: 0.1311 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0101 - accuracy: 0.9957 - val_loss: 0.1128 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.1423 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0198 - accuracy: 0.9923 - val_loss: 0.1522 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0265 - accuracy: 0.9911 - val_loss: 0.1273 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0243 - accuracy: 0.9911 - val_loss: 0.0903 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0256 - accuracy: 0.9903 - val_loss: 0.1237 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0180 - accuracy: 0.9934 - val_loss: 0.1590 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.1062 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.1505 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0131 - accuracy: 0.9943 - val_loss: 0.1650 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.1544 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.1702 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.1521 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 0.1259 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.1959 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.1490 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.1602 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.1717 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.1555 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.1610 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.1383 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0075 - accuracy: 0.9969 - val_loss: 0.1308 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.1800 - val_accuracy: 0.9650 - lr: 0.0010\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.1349 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.1464 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 0.1295 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0170 - accuracy: 0.9957 - val_loss: 0.1692 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 132: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.1235 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 133: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.1079 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 134: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0077 - accuracy: 0.9966 - val_loss: 0.1148 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 135: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.1839 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 136: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1782 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 137: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.1869 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 138: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0068 - accuracy: 0.9971 - val_loss: 0.1624 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 139: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1604 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 140: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0081 - accuracy: 0.9969 - val_loss: 0.1829 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 141: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.1157 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 142: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.1394 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 143: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.1647 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 144: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.1563 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 145: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.1986 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 146: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.1247 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 147: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1493 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 148: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0098 - accuracy: 0.9957 - val_loss: 0.1402 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 149: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0081 - accuracy: 0.9969 - val_loss: 0.2304 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 150: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0141 - accuracy: 0.9946 - val_loss: 0.1241 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 151: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.1539 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 152: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.1231 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 153: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.1311 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 154: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.1080 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 155: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.1641 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 156: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1524 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 157: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.1331 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 158: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.1502 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 159: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.1442 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 160: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0058 - accuracy: 0.9977 - val_loss: 0.1467 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 161: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1369 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 162: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.2027 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 163: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 163/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0073 - accuracy: 0.9969 - val_loss: 0.1508 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 164: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.2506 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 165: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 165/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0091 - accuracy: 0.9966 - val_loss: 0.1311 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 166: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.1432 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 167: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0062 - accuracy: 0.9974 - val_loss: 0.1533 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 168: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0062 - accuracy: 0.9971 - val_loss: 0.1456 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 169: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 169/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.1367 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 170: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.1051 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 171: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.1234 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 172: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 172/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.1174 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 173: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 173/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.2142 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 174: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.1008 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 175: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.1553 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 176: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.1202 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 177: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.1598 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 178: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.1390 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 179: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0079 - accuracy: 0.9969 - val_loss: 0.1662 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 180: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.2107 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 181: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.1309 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 182: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 182/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.1801 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 183: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 183/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.1344 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 184: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 184/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1645 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 185: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 185/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1725 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 186: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1966 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 187: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 187/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.2007 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 188: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 188/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1968 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 189: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 189/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.1700 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 190: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 190/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0032 - accuracy: 0.9986 - val_loss: 0.1540 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 191: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 191/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.1561 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 192: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 192/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.1425 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 193: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 193/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0050 - accuracy: 0.9980 - val_loss: 0.1075 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 194: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 194/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.2106 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 195: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 195/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 0.2130 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "\n",
      "Epoch 196: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 196/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.1781 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 197: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 197/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0048 - accuracy: 0.9980 - val_loss: 0.1707 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "\n",
      "Epoch 198: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 198/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.2208 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "\n",
      "Epoch 199: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 199/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.2463 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "\n",
      "Epoch 200: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 200/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.2225 - val_accuracy: 0.9750 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# 1. Import libraries and modules\n",
    "%load_ext tensorboard\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import numpy as np\n",
    "from dataset import load_hoda\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(123)  # for reproducibility\n",
    "\n",
    "# Load pre-shuffled HODA data into train and test sets\n",
    "x_train_original, y_train_original, x_test_original, y_test_original = load_hoda(\n",
    "                                                                        training_sample_size=3500,\n",
    "                                                                        test_sample_size=400,size=28)\n",
    "\n",
    "# Preprocess input data\n",
    "''' 3.1: input data in numpy array format'''\n",
    "x_train = np.array(x_train_original)\n",
    "x_test = np.array(x_test_original)\n",
    "'''3.2 normalize our data values to the range [0, 1]'''\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Reshape to original image shape (n x 784)  ==> (n x 28 x 28 x 1)\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "\n",
    "# 4. Preprocess class labels\n",
    "y_train = keras.utils.to_categorical(y_train_original, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test_original, num_classes=10)\n",
    "\n",
    "\n",
    "# test and validation set\n",
    "x_val = x_test[:200]\n",
    "x_test = x_test[200:]\n",
    "y_val = y_test[:200]\n",
    "y_test = y_test[200:]\n",
    "\n",
    "# 5. Define model architecture\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# 6. Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 7. Fit model on training data\n",
    "def schedule(epoch):\n",
    "    return 1e-3\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "lr = keras.callbacks.LearningRateScheduler(schedule, verbose=1)\n",
    "history = model.fit(x_train, y_train,\n",
    "          epochs=200, batch_size=256, validation_data = (x_val, y_val), callbacks=[lr, tensorboard])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13712), started 0:36:21 ago. (Use '!kill 13712' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e0f253c557ab3a5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e0f253c557ab3a5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtuUlEQVR4nO3dfZxUdd3/8deH5Wa5U2RBQe4WC0V9KHcrBKhhWYIapHkDoonWhaBmVuYPL8q8NLry0tLMuzBF003QTMOCNMi8yVJWBBQURQRdFEIU5FbuPr8/vmd2Zmdndmdhd2dn9v18PM5jzt2c8znfc+Yz3/meM+eYuyMiIrmvWbYDEBGRuqGELiKSJ5TQRUTyhBK6iEieUEIXEckTSugiInlCCT2PmdlcM7uwrufNJjNbZWYn18Ny3cw+H/XfbWY/zmTefVjPeDN7el/jFKmO6Tr0xsXMtiQMtgE+A/ZEw5e4e2nDR9V4mNkq4NvuPq+Ol+tAH3dfUVfzmlkx8C7Qwt1310mgItVonu0ApDJ3bxfrry55mVlzJQlpLHQ8Ng5qcskRZjbCzMrN7P+Z2VpghpkdZGZ/NrP1ZvZJ1N894T3/MLNvR/0TzOwFM7s5mvddMxu1j/P2NrPnzGyzmc0zszvM7KE0cWcS4w1m9s9oeU+bWaeE6ReY2Woz22BmU6spnyFmttbMChLGnWFmS6L+wWb2LzPbaGYfmtntZtYyzbLuN7OfJgz/MHrPB2Z2cdK8p5nZq2b2qZm9b2bXJUx+LnrdaGZbzGxorGwT3j/MzBaY2abodVimZVPLcu5oZjOibfjEzJ5ImDbGzBZF2/COmY2Mxldq3jKz62L72cyKo6anb5nZe8Dfo/GPRvthU3SMHJ3w/tZm9otof26KjrHWZvYXM/tO0vYsMbMzUm2rpKeEnlu6AB2BXsBEwv6bEQ33BLYDt1fz/iHAcqAT8H/AvWZm+zDv74GXgSLgOuCCataZSYznARcBBwMtgasAzOwo4K5o+YdG6+tOCu7+ErAV+FLScn8f9e8Bvhdtz1Dgy8Cl1cRNFMPIKJ6vAH2A5Pb7rcA3gQ7AacBkM/t6NO3E6LWDu7dz938lLbsj8Bfgtmjbfgn8xcyKkrahStmkUFM5P0howjs6WtYtUQyDgd8BP4y24URgVZp1pPJF4EjglGh4LqGcDgYWAolNhDcDg4BhhOP4amAv8ABwfmwmM+sHdCOUjdSGu6trpB3hg3Vy1D8C2AkUVjN/f+CThOF/EJpsACYAKxKmtQEc6FKbeQnJYjfQJmH6Q8BDGW5Tqhh/lDB8KfDXqP9aYGbCtLZRGZycZtk/Be6L+tsTkm2vNPNeCTyeMOzA56P++4GfRv33AT9PmO/wxHlTLPdW4Jaovziat3nC9AnAC1H/BcDLSe//FzChprKpTTkDXQmJ86AU8/0mFm91x180fF1sPyds22HVxNAhmudAwhfOdqBfivkKgU8I5yUgJP476+Mzle+daui5Zb2774gNmFkbM/tN9BP2U8JP/A6JzQ5J1sZ63H1b1NuulvMeCnycMA7g/XQBZxjj2oT+bQkxHZq4bHffCmxIty5CbfxMM2sFnAksdPfVURyHR80Qa6M4fkaordekUgzA6qTtG2Jmz0RNHZuASRkuN7bs1UnjVhNqpzHpyqaSGsq5B2GffZLirT2AdzKMN5WKsjGzAjP7edRs8ynxmn6nqCtMta7omJ4FnG9mzYBxhF8UUktK6Lkl+ZKkHwBHAEPc/QDiP/HTNaPUhQ+BjmbWJmFcj2rm358YP0xcdrTOonQzu/syQkIcReXmFghNN28SaoEHAP+9LzEQfqEk+j0wG+jh7gcCdycst6ZLyD4gNJEk6gmsySCuZNWV8/uEfdYhxfveBz6XZplbCb/OYrqkmCdxG88DxhCapQ4k1OJjMXwE7KhmXQ8A4wlNYds8qXlKMqOEntvaE37GbozaY39S3yuMarxlwHVm1tLMhgJfq6cY/wCcbmbHRycwr6fmY/b3wHcJCe3RpDg+BbaYWV9gcoYxPAJMMLOjoi+U5PjbE2q/O6L26PMSpq0nNHUclmbZc4DDzew8M2tuZucCRwF/zjC25DhSlrO7f0ho274zOnnawsxiCf9e4CIz+7KZNTOzblH5ACwCxkbzlwBnZRDDZ4RfUW0Iv4JiMewlNF/90swOjWrzQ6NfU0QJfC/wC1Q732dK6LntVqA1ofbzb+CvDbTe8YQTixsI7dazCB/kVG5lH2N096XAZYQk/SGhnbW8hrc9TDhR93d3/yhh/FWEZLsZuCeKOZMY5kbb8HdgRfSa6FLgejPbTGjzfyThvduAacA/LVxd84WkZW8ATifUrjcQThKenhR3pm6l+nK+ANhF+JXyH8I5BNz9ZcJJ11uATcCzxH81/JhQo/4E+B8q/+JJ5XeEX0hrgGVRHImuAl4DFgAfAzdSOQf9DjiGcE5G9oH+WCT7zcxmAW+6e73/QpD8ZWbfBCa6+/HZjiVXqYYutWZmx5nZ56Kf6CMJ7aZPZDksyWFRc9alwPRsx5LLlNBlX3QhXFK3hXAN9WR3fzWrEUnOMrNTCOcb1lFzs45UQ00uIiJ5QjV0EZE8kbWbc3Xq1MmLi4uztXoRkZz0yiuvfOTunVNNy1pCLy4upqysLFurFxHJSWaW/O/iCmpyERHJE0roIiJ5QgldRCRPKKGLiOQJJXQRkTxRY0I3s/vM7D9m9nqa6WZmt5nZiuixUQPrPkwRyRelpVBcDM2ahdfSLD32vLo4YtPMwnSz0HXqlFm8ycu+9NIG2uaanoBBuA3pQOD1NNNPJdya04AvAC9l8mSNQYMGuTQ9Dz3k3quXu1l4feih1NOKitzbtnWH0LVtG8bFplXXD2E49t5mzaqOS1xeYhyxGJLnT+yKiirHnW4bwb2gIP6exO2JxZQ8PpOuqMh98uTK5Rgbri7uTLpYuSTGXtM21NX69yfuTLpUx0E2u5qOo3SAMk+RUz0sNqPHWRVXk9B/A4xLGF4OdK1pmUro2VVdYk2enpg0Ez+8mb63tgkrl7rkD+XkyY0nYahr/F2bNrVP6vWd0P8MHJ8wPB8oSTPvRMLDEcp69uxZu60Qd685EcfmidWyoHKtS8lGnbrG1fXqVbscUF1Cb9CTou4+3d1L3L2kc+eU/1xt8tK165WWhva788+H1avDobB6dRiOte+1axe688+HDQlP3ty6NT7s3tBbJCLVee+9ultWXST0NVR+5mJ39u2ZiE1CqoSdeALmggtSJ+zkJJ3K1q2hE5Hc0TP5KbX7oS7u5TIbuNzMZgJDgE0enmGYd7Zvh8LCkGAzVVoK3/1u6mQcS9iJVIMWaTratIFp0+pueZlctvgw8C/gCDMrN7NvmdkkM5sUzTIHWEl43uI9hKeO5KXhw2HoUNi4MT4ukyaSmmrWUr+aRUd5bb6IpX61bQtFRaG/oCC8Zmv/tGtXdf2xY6ZXL3jooVDReuiheMzVib23qKjq/LFxZmHZ06fD+PH7vw0V0jWu13eXa1e5rFoVP4lx1FHuw4e7t29f9QRHq1Zhuk4+pu5i5dK6tXvHjpXHQdXLCadMcT/++PiVMh07hveCe8uWoYstI7acli3d777b/b333C+5xP38893vvz++LxMvK2zTJnSx9ccubevZ0/2889xfeKHycZB8wrm6LvHyQnA/4AD3X/7Sfc8e93POce/SJf3J7TvvjMdz5JFhG/74x8qxx463xDLs0cP91FPD/Oef7z5hgvuCBemP69h6pk1zb9fOvbAwDLdrF47x0tKwzs6dveIEXnWXeB5wQLx/5Ej3bdvclywJ7z/44LBvYtuT3F1yifvq1TV/Fl94wf3CC92/+U33556rOv3ee92ffNJ9795wHMyc6f6Xv4SYvv999/HjK+/v4mL3zz6reb3uYXu6dIkfJ+B+8cXul10W+v/xjzDfpk3ukya5n3VWKI/arqc67O9VLvXRNXRC37XLfceOyuM2bHB/9133LVsqj//00zB+48b4uBkzQmn9/OfuBx2U/cTYEF3r1u4dOsSTU3IiS0yEqboDDqic3Fq0cO/f37137zBu+vRQtmvXhvJO7mbODO8pKgqJZsQI96eeCu/t1s39sMPi3Re+4P7WW+GD27JlfD2tW7t37RpPWu++6751a1jvgAFh/Omnh/WA+4svhmlPPx2GCwtDf6Jt28JybrklXj6JXwbdu4dpicfbb38bpo0Z4/7oo6G/fXv3f/4zTN+71/3998NyV6wIyxg+PGzP0UeHY+6gg+LH5Fe/Gi/jn/0s9Hfp4j50aIgjVi4HHlh5PTFbtlRez9694diOLaewMJR7mzZhvo4d3Zs3D/ElS9yetm3dx40L22vmfuKJYTndusX3z9FHV953sa5165D0YuvYsyeUdaJ588J8sfIoLAzHRMyyZfEEOmZMfN8cckg4HnbuDMv9/vfjX5Lg/otfpD4Gk7sbbgjzz53rfvbZ7lOnhrLbti0cZyeeGIZ/8pMw32GHhS+Q2Hpuvjks59NPq5ZjppTQPXybDxwYdqZ7+PDEajdFRe6vvBLGP/98PBG1bh0/WE44ofHUutu0yewyxJYtwzYeckh83PXXu//gB6H/yivdTzop9H/72+5f+1roHzs2fChj7ykudl+5MtQuYjWyoUNDDTY2zwcfhHL7xjdC2cZqzuB+1VXhIJ8zJ8TToYP7oYe6n3xyqGFVtw1Dhrh/8on7r34VT+Q9elT9ck40d258PQsWhC/zxO059lj3N98M/UcfHV4HD3bv1Ckkyr17wxdEjx5h3lat3P/617DsZcviXxCxrn9/9/Xrw/Tbb49vT3Gx+zvvxMst9qXRrZt7nz6ha9fO/dlnw/GZvO3z5sW3qawsvv927gzHwJFHhnEFBe6DBoX9XFDg/sgj8feVl8fX8/zzYdzChWFbk9ezeXOoSXfo4P7yy+7Ll4fE2L17mK9Fi3CcJNqzJ5Rhnz7uhx8e5n/jjTBtxoxQFt27u7/9ds2f0bKykKR79nRftCj8MuvSxX3p0jD9qadCAj/mGPd160KZx/bP3LlhnnPPDV8qX/xiiPlb33IfPTr033tv1XXG9nVtPn9f/nLq+H/96zD9hhvCZ+HMM9Ov5667ai6PdJTQPX5QzpwZhn/xizB8663hAOrQIfw8bds2HESJtdFY4s9216FD+Mme7KGH4s0QiUn/1792P+KI+Lif/SzMv2NH+GkYq1k8/XT4YH72WfjQ7NoVusceCwfeQQeF8hs1Kp5kmzcPCS/WbHLppZWTw4svhg/0nDlhPTFLloQkN3Vq+PAPGBAS5IwZVbvS0pBk3N23bw9fAuD+m9/UvL9j64nZvTvUkqZMCcs47rjw+t577vPnhxrTTTeFcbEvtrvvDkmjf//wBfXNb4Zmg0MOCb8uZswI+6OwMJTz2WeH9516aii3jh1D8o6V28yZ8V93Dz/svmZN5f1z5ZXxbf/zn6tu05gxocb9+OPx5cXK/4UXwhdpWVnV98XW07ZtOMZjSfO3v626nuXLK9fCY180p5/u/p3vhC+MCRPcL7oodLFa8MMPh1+8yc07L70UvuwztXBhfJuaNw9fPJ07hyaWVq1CAo99ebq7f/RRfP+MHx++QK65pupxHTveU3nvvdTHX6ru/vvTb8/One5nnBHfn4sXp1/Pm29mXibJmnxCX7s2Xsh9+4YP95AhIZm4hwN46NCQoPr2rZocG6qL1exi7ZTbtoWD9IYbat7GdH84+uAD9y99KfUXQaZefdW9X79QPuecE2+OgPDTNfbh69w5fBFkYsmS+DJ+/evM3vP734ca9P60Q8ZqlOA+bFjlaVu3xo+DESPi69mwwf2UU8L4QYPiNdCYefPCcdOjR0hysfclltvZZ4eEMn16SIK7d4d5Pvgg1Pgy2T9LloRjs3nzEP/69e7/+7/uEyfW/N4PPgjb1KNHqCmmajpJZeXK8OW3ZElYxjHHhGUkdqNGxbenLixaFGJ8/PGQ+EpKwnq++tWQwJMl7p8BA1LP01B27gz744c/rL91NPmEHjshcsUVXvEzDEKbYUzyyaa6TtSTJrl//evxcd271/wX+sZq69Z488Ff/xraCSFsT6b27g1NBt26hdp3Q/rDH0K8t97asOutC3//e/j11b9/tiORbKkuoWftmaINqawsXCb005+GP97ce28Yf/bZ4bW0FCZOhG3b6n7dRUXwq1/FL02aNw8GDoSOHet+XQ2lTRsYMgReeAEGDYKSEli5Es45J/NlmMHjj4evt8LC+os1lTPPhDlz4Mtfbtj11oWTToJFi+KXxokkyuuEvmdPOPDLyqBvX2jfPlz3edBB4drwf/0LvvSl8AeffVVUFBLZAw9U/kIwg0mT4M47K89/8sn7vq7G5Nvfhq5dw7X2554LmzbBCSfUbhlHHFE/sdXEDEaNys6660KfPtmOQBorCzX4hldSUuJlZWX1tnx3OO00WLcO3n8fRo6E3/0uPn1/a+XJNe/SUpg6NdyXoWfP8O+vOv3DgIgIYGavuHtJqml5W0OfPx/mzo0PlyRt/ne/W/tknq7WDSF5K4GLSDblZUucO/zkJ9CjR0jqJSWhtg7xv+TX9u/4vXrBgw+mTuYiIo1BXtbQn34aXnwR7r47NLWMHBnG70szS5s29XC/BRGRepB3NXR3uPbaUKO+6KLK06ZOzSyZx27SUy83zxERqSd5V0OfOxdefhnuuQdatqw8LZOrWXr10glNEclNeZXQY7Xz3r3hwgsrTystDTXvdBf1qGlFRHJdXiX0J5+EV16B++6DFi3i40tLQ4JPl8yTL0EUEclFeZPQY1e2fO5z4TFuMbEToXv2pH/vRx/Vf3wiIvUtbxL600+Hv0Tffz80T9iqmq4379WrviMTEWkYeXOVy9y54Z4gY8fGx5WWVn+9eV0/z09EJJvyJqE/80x45merVvFxU6emn7+gQCdBRSS/5EVC/+gjWLIERoyIjystrf4yxQceUDIXkfySFwn9uefC60knhdfYidB0ioqUzEUk/2SU0M1spJktN7MVZjYlxfReZjbfzJaY2T/MrHvdh5reM8+E9vDjjgvD1f0jtE2bcImiiEi+qTGhm1kBcAcwCjgKGGdmRyXNdjPwO3c/Frge+N+6DrQ68+fD8cfH/xn63nvp51W7uYjkq0xq6IOBFe6+0t13AjOBMUnzHAX8Pep/JsX0erNsGbzxBpx+ehguLU3/NJdevZTMRSR/ZZLQuwHvJwyXR+MSLQbOjPrPANqbWVHygsxsopmVmVnZ+vXr9yXeKh59NPyl/xvfqP5PRLpEUUTyXV2dFL0K+KKZvQp8EVgDVEmr7j7d3UvcvaRz5877vVJ3mDULTjwRDj00fdu5LlEUkaYgk3+KrgF6JAx3j8ZVcPcPiGroZtYO+Ia7b6yjGNNaujQ0t1x+eRhO13a+d6+SuYjkv0xq6AuAPmbW28xaAmOB2YkzmFknM4st6xrgvroNM7Vnnw2vX/taeO3ZM/V86caLiOSTGhO6u+8GLgeeAt4AHnH3pWZ2vZmNjmYbASw3s7eAQ4AGaa3+8MPQnHLooWF42rTQVp5Ibeci0lRkdHMud58DzEkad21C/x+AP9RtaDVbtw46dw5JHeLNKlOnhuaXnj31sAoRaTpy+m6La9dCly6Vx40frwQuIk1TTv/1f906OOSQ+HBpKRQXh+vQi4vDsIhIU5HzNfSjov+sxq5Bj122uHp1/H4uqrGLSFOQszV091BDjzW5pLoGfdu26m+hKyKST3I2oW/cCDt3xptc0l2DXt19XURE8knOJvR168JrrIaua9BFpKnL2YS+dm14PeSQ0H6+ZUvVeXQNuog0JTmf0MvKwsnP5GeHFhXp/i0i0rTkbEKPNbn8+tepb8jVrp2SuYg0LTmb0NeuhRYtoLw89XSdDBWRpiZnE3rsT0W9eqWerpOhItLU5GxCX7s2JHTdkEtEJMjZhB77U9H48eHkZ69e4clFvXrpZKiINE05+9f/tWuhf//QrxtyiYjkcA190ybo0CHbUYiINB45mdDdYft2aN0625GIiDQeOZnQd+8OzwlVQhcRicvJhL59e3hVQhcRiVNCFxHJEzmd0AsLsxuHiEhjktMJvXVrPXZORCQmo4RuZiPNbLmZrTCzKSmm9zSzZ8zsVTNbYman1n2ocbGE/vLL4U6Lq1eHK19ij51TUheRpqjGhG5mBcAdwCjgKGCcmR2VNNuPgEfcfQAwFrizrgNNFEvopaV67JyISEwmNfTBwAp3X+nuO4GZwJikeRw4IOo/EPig7kKsKpbQ//Of1NN1p0URaYoySejdgPcThsujcYmuA843s3JgDvCdVAsys4lmVmZmZevXr9+HcINYQo89fi6Z7rQoIk1RXZ0UHQfc7+7dgVOBB82syrLdfbq7l7h7SefOnfd5ZbGEfuWVutOiiEhMJgl9DdAjYbh7NC7Rt4BHANz9X0Ah0KkuAkwlltDPPlt3WhQRicnkbosLgD5m1puQyMcC5yXN8x7wZeB+MzuSkND3vU2lBomXLepOiyIiQY01dHffDVwOPAW8QbiaZamZXW9mo6PZfgD8l5ktBh4GJri711fQ+qeoiEhVGd0P3d3nEE52Jo67NqF/GTC8bkNLTwldRKSqnP2nqBm0bJntSEREGo+cTeitW4ekLiIiQU4ndBERiVNCFxHJE0roIiJ5ImcTuu6FLiJSWU4m9B07VEMXEUmWkwldTS4iIlUpoYuI5AkldBGRPJGzCX3dOj1LVEQkUUb3cmlsPv4YVq2CPXvCcOxZoqA7L4pI05WTNfRNm+LJPEbPEhWRpi4nE/revanH61miItKU5VxCr+4u63qWqIg0ZTmX0HfsCK8tWlQer2eJikhTl3MJPfZwi3PP1bNERUQS5dxVLrGEfsIJ8OCD2Y1FRKQxydkauv5YJCJSmRK6iEieUEIXEckTOZvQdT90EZHKMkroZjbSzJab2Qozm5Ji+i1mtijq3jKzjXUeaUQ1dBGR1Gq8ysXMCoA7gK8A5cACM5vt7sti87j79xLm/w4woB5iBZTQRUTSyaSGPhhY4e4r3X0nMBMYU83844CH6yK4VJTQRURSyyShdwPeTxguj8ZVYWa9gN7A39NMn2hmZWZWtn79+trGCiihi4ikU9cnRccCf3D3Pakmuvt0dy9x95LOnTvv0wpif/1XQhcRqSyThL4G6JEw3D0al8pY6rG5BVRDFxFJJ5OEvgDoY2a9zawlIWnPTp7JzPoCBwH/qtsQKxs+HG64QQldRCRZjVe5uPtuM7sceAooAO5z96Vmdj1Q5u6x5D4WmOle3Q1u99/QoaETEZHKMro5l7vPAeYkjbs2afi6ugtLRERqK+f+KSoiIqkpoYuI5AkldBGRPKGELiKSJ5TQRUTyhBK6iEieUEIXEckTSugiInlCCV1EJE8ooYuI5AkldBGRPKGELiKSJ5TQRUTyhBK6iEieUEIXEckTSugiInlCCV1EJE8ooYuI5AkldBGRPKGELiKSJ5TQRUTyREYJ3cxGmtlyM1thZlPSzHOOmS0zs6Vm9vu6DbOy0lIoLoZmzcJraWl9rk1EJDc0r2kGMysA7gC+ApQDC8xstrsvS5inD3ANMNzdPzGzg+sr4NJSmDgRtm0Lw6tXh2GA8ePra60iIo1fJjX0wcAKd1/p7juBmcCYpHn+C7jD3T8BcPf/1G2YcVOnxpN5zLZtYbyISFOWSULvBryfMFwejUt0OHC4mf3TzP5tZiNTLcjMJppZmZmVrV+/fp8Cfu+92o0XEWkq6uqkaHOgDzACGAfcY2Ydkmdy9+nuXuLuJZ07d96nFfXsWbvxIiJNRSYJfQ3QI2G4ezQuUTkw2913ufu7wFuEBF/npk2DNm0qj2vTJowXEWnKMknoC4A+ZtbbzFoCY4HZSfM8QaidY2adCE0wK+suzLjx42H6dOjVC8zC6/TpOiEqIlLjVS7uvtvMLgeeAgqA+9x9qZldD5S5++xo2lfNbBmwB/ihu2+or6DHj1cCFxFJZu6elRWXlJR4WVlZVtYtIpKrzOwVdy9JNU3/FBURyRNK6CIieUIJXUQkTyihi4jkCSV0EZE8oYQuIpInlNBFRPKEErqISJ5QQhcRyRNK6CIieUIJXUQkTyihi4jkCSV0EZE8oYQuIpInlNBFRPKEErqISJ5QQhcRyRNK6CIieUIJXUQkTyihi4jkCSV0EZE8kVFCN7ORZrbczFaY2ZQU0yeY2XozWxR13677UEVEpDrNa5rBzAqAO4CvAOXAAjOb7e7Lkmad5e6X10OMIiKSgUxq6IOBFe6+0t13AjOBMfUbloiI1FYmCb0b8H7CcHk0Ltk3zGyJmf3BzHqkWpCZTTSzMjMrW79+/T6EKyIi6dTVSdEngWJ3Pxb4G/BAqpncfbq7l7h7SefOneto1SIiApkl9DVAYo27ezSugrtvcPfPosHfAoPqJjwREclUJgl9AdDHzHqbWUtgLDA7cQYz65owOBp4o+5CFBGRTNR4lYu77zazy4GngALgPndfambXA2XuPhu4wsxGA7uBj4EJ9RiziIikYO6elRWXlJR4WVlZVtYtIpKrzOwVdy9JNU3/FBURyRNK6CIieUIJXUQkTyihi4jkCSV0EZE8oYQuIpInlNBFRPKEErqISJ5QQhcRyRNK6CIieUIJXUQkTyihi4jkCSV0EZE8UePtc0Uk/+zatYvy8nJ27NiR7VAkjcLCQrp3706LFi0yfo8SukgTVF5eTvv27SkuLsbMsh2OJHF3NmzYQHl5Ob179874fWpyEWmCduzYQVFRkZJ5I2VmFBUV1foXlBK6SBOlZN647cv+UUIXEckTSugiUqPSUiguhmbNwmtp6f4tb8OGDfTv35/+/fvTpUsXunXrVjG8c+fOat9bVlbGFVdcUeM6hg0btn9B5iCdFBWRapWWwsSJsG1bGF69OgwDjB+/b8ssKipi0aJFAFx33XW0a9eOq666qmL67t27ad48dXoqKSmhpCTlIzUrefHFF/ctuBymGrqIVGvq1Hgyj9m2LYyvSxMmTGDSpEkMGTKEq6++mpdffpmhQ4cyYMAAhg0bxvLlywH4xz/+wemnnw6EL4OLL76YESNGcNhhh3HbbbdVLK9du3YV848YMYKzzjqLvn37Mn78eNwdgDlz5tC3b18GDRrEFVdcUbHcRKtWreKEE05g4MCBDBw4sNIXxY033sgxxxxDv379mDJlCgArVqzg5JNPpl+/fgwcOJB33nmnbguqGhnV0M1sJPAroAD4rbv/PM183wD+ABzn7mV1FqWIZM1779Vu/P4oLy/nxRdfpKCggE8//ZTnn3+e5s2bM2/ePP77v/+bxx57rMp73nzzTZ555hk2b97MEUccweTJk6tcu/3qq6+ydOlSDj30UIYPH84///lPSkpKuOSSS3juuefo3bs348aNSxnTwQcfzN/+9jcKCwt5++23GTduHGVlZcydO5c//elPvPTSS7Rp04aPP/4YgPHjxzNlyhTOOOMMduzYwd69e+u+oNKoMaGbWQFwB/AVoBxYYGaz3X1Z0nztge8CL9VHoCKSHT17hmaWVOPr2tlnn01BQQEAmzZt4sILL+Ttt9/GzNi1a1fK95x22mm0atWKVq1acfDBB7Nu3Tq6d+9eaZ7BgwdXjOvfvz+rVq2iXbt2HHbYYRXXeY8bN47p06dXWf6uXbu4/PLLWbRoEQUFBbz11lsAzJs3j4suuog2bdoA0LFjRzZv3syaNWs444wzgPDnoIaUSZPLYGCFu690953ATGBMivluAG4E9NczkTwybRpEOatCmzZhfF1r27ZtRf+Pf/xjTjrpJF5//XWefPLJtNdkt2rVqqK/oKCA3bt379M86dxyyy0ccsghLF68mLKyshpP2mZTJgm9G/B+wnB5NK6CmQ0Eerj7X6pbkJlNNLMyMytbv359rYMVkYY3fjxMnw69eoFZeJ0+fd9PiGZq06ZNdOsWUs39999f58s/4ogjWLlyJatWrQJg1qxZaePo2rUrzZo148EHH2TPnj0AfOUrX2HGjBlsi04wfPzxx7Rv357u3bvzxBNPAPDZZ59VTG8I+31S1MyaAb8EflDTvO4+3d1L3L2kc+fO+7tqEWkg48fDqlWwd294re9kDnD11VdzzTXXMGDAgFrVqDPVunVr7rzzTkaOHMmgQYNo3749Bx54YJX5Lr30Uh544AH69evHm2++WfErYuTIkYwePZqSkhL69+/PzTffDMCDDz7IbbfdxrHHHsuwYcNYu3ZtnceejsXO9qadwWwocJ27nxINXwPg7v8bDR8IvANsid7SBfgYGF3didGSkhIvK9N5U5FseOONNzjyyCOzHUbWbdmyhXbt2uHuXHbZZfTp04fvfe972Q6rQqr9ZGavuHvK6zYzqaEvAPqYWW8zawmMBWbHJrr7Jnfv5O7F7l4M/JsakrmISGNwzz330L9/f44++mg2bdrEJZdcku2Q9kuNV7m4+24zuxx4inDZ4n3uvtTMrgfK3H129UsQEWmcvve97zWqGvn+yug6dHefA8xJGndtmnlH7H9YIiJSW/qnqIhInlBCFxHJE0roIiJ5QgldRBrcSSedxFNPPVVp3K233srkyZPTvmfEiBHELnU+9dRT2bhxY5V5rrvuuorrwdN54oknWLYsfueSa6+9lnnz5tUi+sZLCV1EGty4ceOYOXNmpXEzZ85Me4OsZHPmzKFDhw77tO7khH799ddz8skn79OyGhvdD12kibvySohuTV5n+veHW29NP/2ss87iRz/6ETt37qRly5asWrWKDz74gBNOOIHJkyezYMECtm/fzllnncX//M//VHl/cXExZWVldOrUiWnTpvHAAw9w8MEH06NHDwYNGgSEa8ynT5/Ozp07+fznP8+DDz7IokWLmD17Ns8++yw//elPeeyxx7jhhhs4/fTTOeuss5g/fz5XXXUVu3fv5rjjjuOuu+6iVatWFBcXc+GFF/Lkk0+ya9cuHn30Ufr27VspplWrVnHBBRewdetWAG6//faKh2zceOONPPTQQzRr1oxRo0bx85//nBUrVjBp0iTWr19PQUEBjz76KJ/73Of2q9xVQxeRBtexY0cGDx7M3LlzgVA7P+ecczAzpk2bRllZGUuWLOHZZ59lyZIlaZfzyiuvMHPmTBYtWsScOXNYsGBBxbQzzzyTBQsWsHjxYo488kjuvfdehg0bxujRo7nppptYtGhRpQS6Y8cOJkyYwKxZs3jttdfYvXs3d911V8X0Tp06sXDhQiZPnpyyWSd2m92FCxcya9asiqcqJd5md/HixVx99dVAuM3uZZddxuLFi3nxxRfp2rXr/hUqqqGLNHnV1aTrU6zZZcyYMcycOZN7770XgEceeYTp06eze/duPvzwQ5YtW8axxx6bchnPP/88Z5xxRsUtbEePHl0x7fXXX+dHP/oRGzduZMuWLZxyyinVxrN8+XJ69+7N4YcfDsCFF17IHXfcwZVXXgmELwiAQYMG8cc//rHK+xvDbXZzqoZe1881FJHsGTNmDPPnz2fhwoVs27aNQYMG8e6773LzzTczf/58lixZwmmnnZb2trk1mTBhArfffjuvvfYaP/nJT/Z5OTGxW/Cmu/1uY7jNbs4k9NhzDVevBvf4cw2V1EVyU7t27TjppJO4+OKLK06Gfvrpp7Rt25YDDzyQdevWVTTJpHPiiSfyxBNPsH37djZv3syTTz5ZMW3z5s107dqVXbt2UZqQKNq3b8/mzZurLOuII45g1apVrFixAgh3TfziF7+Y8fY0htvs5kxCb6jnGopIwxk3bhyLFy+uSOj9+vVjwIAB9O3bl/POO4/hw4dX+/6BAwdy7rnn0q9fP0aNGsVxxx1XMe2GG25gyJAhDB8+vNIJzLFjx3LTTTcxYMCASs/7LCwsZMaMGZx99tkcc8wxNGvWjEmTJmW8LY3hNrs13j63vtT29rnNmoWaeTKzcI9mEcmcbp+bG+rj9rmNQrrnF9bHcw1FRHJRziT0hnyuoYhILsqZhJ6t5xqK5KtsNbdKZvZl/+TUdejjxyuBi9SFwsJCNmzYQFFREWaW7XAkibuzYcOGWl+fnlMJXUTqRvfu3SkvL2f9+vXZDkXSKCwspHv37rV6jxK6SBPUokULevfune0wpI7lTBu6iIhUTwldRCRPKKGLiOSJrP1T1MzWA6v38e2dgI/qMJy61FhjU1y1o7hqr7HGlm9x9XL3zqkmZC2h7w8zK0v319dsa6yxKa7aUVy111hja0pxqclFRCRPKKGLiOSJXE3o07MdQDUaa2yKq3YUV+011tiaTFw52YYuIiJV5WoNXUREkiihi4jkiZxL6GY20syWm9kKM5uSxTh6mNkzZrbMzJaa2Xej8deZ2RozWxR1p2YhtlVm9lq0/rJoXEcz+5uZvR29HtTAMR2RUCaLzOxTM7syW+VlZveZ2X/M7PWEcSnLyILbomNuiZkNbOC4bjKzN6N1P25mHaLxxWa2PaHs7m7guNLuOzO7Jiqv5WZ2Sn3FVU1ssxLiWmVmi6LxDVJm1eSH+j3G3D1nOqAAeAc4DGgJLAaOylIsXYGBUX974C3gKOA64Kosl9MqoFPSuP8DpkT9U4Abs7wf1wK9slVewInAQOD1msoIOBWYCxjwBeClBo7rq0DzqP/GhLiKE+fLQnml3HfR52Ax0AroHX1mCxoytqTpvwCubcgyqyY/1Osxlms19MHACndf6e47gZnAmGwE4u4fuvvCqH8z8AbQLRuxZGgM8EDU/wDw9eyFwpeBd9x9X/8pvN/c/Tng46TR6cpoDPA7D/4NdDCzrg0Vl7s/7e67o8F/A7W7p2o9xVWNMcBMd//M3d8FVhA+uw0em4WbvZ8DPFxf608TU7r8UK/HWK4l9G7A+wnD5TSCJGpmxcAA4KVo1OXRz6b7GrppI+LA02b2iplNjMYd4u4fRv1rgUOyEFfMWCp/wLJdXjHpyqgxHXcXE2pyMb3N7FUze9bMTshCPKn2XWMqrxOAde7+dsK4Bi2zpPxQr8dYriX0RsfM2gGPAVe6+6fAXcDngP7Ah4Sfew3teHcfCIwCLjOzExMneviNl5XrVc2sJTAaeDQa1RjKq4psllE6ZjYV2A2URqM+BHq6+wDg+8DvzeyABgypUe67JOOoXHlo0DJLkR8q1McxlmsJfQ3QI2G4ezQuK8ysBWFnlbr7HwHcfZ2773H3vcA91ONPzXTcfU30+h/g8SiGdbGfcNHrfxo6rsgoYKG7r4tizHp5JUhXRlk/7sxsAnA6MD5KBERNGhui/lcIbdWHN1RM1ey7rJcXgJk1B84EZsXGNWSZpcoP1PMxlmsJfQHQx8x6RzW9scDsbAQStc3dC7zh7r9MGJ/Y7nUG8Hrye+s5rrZm1j7WTzih9jqhnC6MZrsQ+FNDxpWgUo0p2+WVJF0ZzQa+GV2J8AVgU8LP5npnZiOBq4HR7r4tYXxnMyuI+g8D+gArGzCudPtuNjDWzFqZWe8orpcbKq4EJwNvunt5bERDlVm6/EB9H2P1fba3rjvC2eC3CN+sU7MYx/GEn0tLgEVRdyrwIPBaNH420LWB4zqMcIXBYmBprIyAImA+8DYwD+iYhTJrC2wADkwYl5XyInypfAjsIrRXfitdGRGuPLgjOuZeA0oaOK4VhPbV2HF2dzTvN6J9vAhYCHytgeNKu++AqVF5LQdGNfS+jMbfD0xKmrdByqya/FCvx5j++i8ikidyrclFRETSUEIXEckTSugiInlCCV1EJE8ooYuI5AkldBGRPKGELiKSJ/4/hPsufNwj2PYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\"> دوره مقدماتی یادگیری عمیق<br>علیرضا اخوان پور<br>پنج شنبه، ۱۸ بهمن ۱۳۹۷<br>\n",
    "</div>\n",
    "<a href=\"http://class.vision\">Class.Vision</a> - <a href=\"http://AkhavanPour.ir\">AkhavanPour.ir</a> - <a href=\"https://github.com/Alireza-Akhavan/\">GitHub</a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "nbpresent": {
   "slides": {
    "300ee14f-a043-486e-b274-7ff253907cd7": {
     "id": "300ee14f-a043-486e-b274-7ff253907cd7",
     "prev": "cb74e0bc-4513-4d13-b7f1-14c3078a7927",
     "regions": {
      "26dc3f39-a230-447c-af4c-f5e5b2fb7835": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c58440a5-3f8f-4f37-9c79-6bf766209406",
        "part": "whole"
       },
       "id": "26dc3f39-a230-447c-af4c-f5e5b2fb7835"
      }
     }
    },
    "878aa53a-1444-4100-8f50-7a408191c579": {
     "id": "878aa53a-1444-4100-8f50-7a408191c579",
     "prev": null,
     "regions": {
      "a6c6843a-5ea6-4fbc-b890-3b4b8ae475b3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "588ee1fa-64b5-453b-ade7-8e6b2515821c",
        "part": "whole"
       },
       "id": "a6c6843a-5ea6-4fbc-b890-3b4b8ae475b3"
      }
     }
    },
    "96ffe88e-7b50-43de-afdd-942e564f4e3e": {
     "id": "96ffe88e-7b50-43de-afdd-942e564f4e3e",
     "prev": "878aa53a-1444-4100-8f50-7a408191c579",
     "regions": {
      "b7e52e12-489a-468d-b10c-af2024fd2856": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "de829a92-1fb6-44ad-a2c6-fc1001e1f6e1",
        "part": "whole"
       },
       "id": "b7e52e12-489a-468d-b10c-af2024fd2856"
      }
     }
    },
    "cb74e0bc-4513-4d13-b7f1-14c3078a7927": {
     "id": "cb74e0bc-4513-4d13-b7f1-14c3078a7927",
     "prev": "96ffe88e-7b50-43de-afdd-942e564f4e3e",
     "regions": {
      "444878ee-68f3-4abb-acff-a7079b21e86d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "25f3f538-1ee8-4d98-a6bb-14cbeb7a702d",
        "part": "whole"
       },
       "id": "444878ee-68f3-4abb-acff-a7079b21e86d"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

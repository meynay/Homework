{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlgS2uPoQD2k"
      },
      "source": [
        "<center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">به نام خدا</div></center>\n",
        "<h1><center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">آموزش یک شبکه عصبی کانولوشنالی از ابتدا</div></center></h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FohNOURJQD2r"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir =  \"/root/.keras/datasets/cats_and_dogs_filtered/train\"\n",
        "validation_dir = \"/root/.keras/datasets/cats_and_dogs_filtered/validation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WDHIC7MdQD2s"
      },
      "outputs": [],
      "source": [
        "def augment_data(image):\n",
        "  image = tf.image.resize_with_crop_or_pad(image, 180, 180)\n",
        "  image = tf.image.random_crop(image, size=[150, 150, 3])\n",
        "  image = tf.image.random_brightness(image, max_delta=0.5)\n",
        "\n",
        "  return image\n",
        "\n",
        "train_dir = pathlib.Path(train_dir)\n",
        "validation_dir = pathlib.Path(validation_dir)\n",
        "\n",
        "class_names = np.array([item.name for item in train_dir.glob('*')])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-y0azuTSQ0w",
        "outputId": "c334919f-56d6-4ee6-de6c-a9e9247df997"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['cats', 'dogs'], dtype='<U4')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.list_files(str(train_dir/'*/*'))"
      ],
      "metadata": {
        "id": "ue-qaQKoUmQE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = tf.data.Dataset.list_files(str(validation_dir/'*/*'))"
      ],
      "metadata": {
        "id": "Ol0xU39jU-nP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label(filepath):\n",
        "  parts = tf.strings.split(filepath, os.path.sep)\n",
        "  return parts[-2] == class_names"
      ],
      "metadata": {
        "id": "VE1tVEVLVMZR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(imagepath):\n",
        "  image = tf.io.read_file(imagepath)\n",
        "  image = tf.image.decode_image(image, 3, expand_animations=False)\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  return image"
      ],
      "metadata": {
        "id": "FgLqSCuzWtwL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(image):\n",
        "  image = (image / 255.0)\n",
        "  return image"
      ],
      "metadata": {
        "id": "MWNBoA8MXlTg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize(image, height, width):\n",
        "  image = tf.image.resize(image, (height, width), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  return image"
      ],
      "metadata": {
        "id": "rg2DJdczYMQr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_with_label(imagepath):\n",
        "  label = get_label(imagepath)\n",
        "  image = load_image(imagepath)\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "W88o194wYvjb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_train(imagefile):\n",
        "  image, label = load_image_with_label(imagefile)\n",
        "  image = augment_data(image)\n",
        "  image = normalize(image)\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "xazPF9MZZROK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_test(imagefile):\n",
        "  image, label = load_image_with_label(imagefile)\n",
        "  image = resize(image, 150, 150)\n",
        "  image = normalize(image)\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "zh5ABljWZjoK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "shuffle_buffer_size = 1000"
      ],
      "metadata": {
        "id": "5aKn9v5wZ-Bq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(load_image_train)\n",
        "train_dataset = train_dataset.shuffle(shuffle_buffer_size)\n",
        "train_dataset = train_dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "LIufACPNaHsS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = validation_dataset.map(load_image_test)\n",
        "validation_dataset = validation_dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "PL3dXO50aojc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))"
      ],
      "metadata": {
        "id": "UoCvfpxbgpTP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "wKoclU18g_p1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)"
      ],
      "metadata": {
        "id": "4AIxMJbZhHjz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "dense_layer = tf.keras.layers.Dense(32, activation='relu')\n",
        "dropout_layer = tf.keras.layers.Dropout(0.5)\n",
        "prediction_layer = tf.keras.layers.Dense(num_classes, activation='softmax')"
      ],
      "metadata": {
        "id": "nYu-QcXBhMUl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential ([\n",
        "      base_model,\n",
        "      flatten_layer,\n",
        "      dense_layer,\n",
        "      dropout_layer,\n",
        "      prediction_layer\n",
        "])"
      ],
      "metadata": {
        "id": "PtwnIRqsh1AR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(tf.keras.optimizers.RMSprop(learning_rate=0.01), loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NFYgeQX4jpHU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, epochs=10, validation_data=validation_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4-qEvLZkJ9O",
        "outputId": "3e7412df-2445-4a3e-e848-d96c57a97e5b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 678s 11s/step - loss: 0.6710 - accuracy: 0.6155 - val_loss: 0.4776 - val_accuracy: 0.7840\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 676s 11s/step - loss: 0.5170 - accuracy: 0.7300 - val_loss: 0.4716 - val_accuracy: 0.7660\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 677s 11s/step - loss: 0.4964 - accuracy: 0.7495 - val_loss: 0.5161 - val_accuracy: 0.7270\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 677s 11s/step - loss: 0.4554 - accuracy: 0.7820 - val_loss: 0.4227 - val_accuracy: 0.7840\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 674s 11s/step - loss: 0.4732 - accuracy: 0.7780 - val_loss: 0.4566 - val_accuracy: 0.7760\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 696s 11s/step - loss: 0.4138 - accuracy: 0.8020 - val_loss: 1.2611 - val_accuracy: 0.5930\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 676s 11s/step - loss: 0.4289 - accuracy: 0.7870 - val_loss: 0.4226 - val_accuracy: 0.8160\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 676s 11s/step - loss: 0.4311 - accuracy: 0.7905 - val_loss: 0.4509 - val_accuracy: 0.8040\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 676s 11s/step - loss: 0.3976 - accuracy: 0.8105 - val_loss: 0.4053 - val_accuracy: 0.7970\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 676s 11s/step - loss: 0.3905 - accuracy: 0.8145 - val_loss: 0.7456 - val_accuracy: 0.7170\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "tensorflow",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "07_CNN-cat_Vs_dog.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
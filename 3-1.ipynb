{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">به نام خدا</div></center>\n",
    "<h1><center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">مقدمه ای بر شبکه‌های عصبی کانولوشنالی<br>Convolutionl Neural Networks - CNN</div></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">مقدمه ای بر شبکه‌های عصبی کانولوشنالی(Convolutionl Neural Networks - CNN)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "در ابتدا معماری شبکه را مشخص میکنیم.\n",
    "<br>\n",
    "به لایه های conv و pool دقت کنید.\n",
    "<br>\n",
    "قبل از اولین لایه Dense یا Fully Connected همیشه متد Flatten فراخوانی میشود تا نورون ها به صورت یک وکتور در بیایند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">اجرا روی Colab</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "اگر روی گوگل کولب اجرا میکنید این خطوط را از حالت کامنت خارج نمائید.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset.py\n",
    "#!mkdir dataset\n",
    "#!wget https://github.com/Alireza-Akhavan/SRU-deeplearning-workshop/raw/master/dataset/Data_hoda_full.mat -P dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import numpy as np\n",
    "from dataset import load_hoda\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "نگاهی به تنسور وردی و خروجی هر لایه بیندازیم.\n",
    "<br>\n",
    "تصویر ورودی 28x28x3 بوده است\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">کد یک شبکه کانولوشنالی و آموزش آن از ابتدا تا انتها بر روی مجموعه داده هدی</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "تصاویر مجموعه داده هدی در تابعی که قبلا نوشته ایم، load_hoda به صورت flat شده و یک وکتور در آمده اند.\n",
    "<br>\n",
    "در این فراخوانی طول و عرض تصاویر 28 قرار داده شده است، پس خروجی این تابع وکتورهای 784تایی است.\n",
    "<br>\n",
    "** دقت کنید که قبل از ورودی شبکه کانولوشنالی تصویر را به شکل اصلی خود یعنی 28x28 برگردانده ایم.**\n",
    "<br>\n",
    "همچنین چون تصاویر سیاه و سفید است تعداد کانال تصویر را 1 قرار داده ایم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 [==============================] - 1s 69ms/step - loss: 2.0411 - accuracy: 0.2991 - val_loss: 1.3198 - val_accuracy: 0.6800\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 1.1937 - accuracy: 0.5903 - val_loss: 0.5682 - val_accuracy: 0.8450\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.7756 - accuracy: 0.7366 - val_loss: 0.3455 - val_accuracy: 0.9000\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.5503 - accuracy: 0.8249 - val_loss: 0.2553 - val_accuracy: 0.9250\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.4339 - accuracy: 0.8529 - val_loss: 0.2085 - val_accuracy: 0.9500\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.3720 - accuracy: 0.8817 - val_loss: 0.1771 - val_accuracy: 0.9500\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.3333 - accuracy: 0.8929 - val_loss: 0.1561 - val_accuracy: 0.9600\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.3228 - accuracy: 0.8877 - val_loss: 0.1489 - val_accuracy: 0.9550\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.2679 - accuracy: 0.9094 - val_loss: 0.1567 - val_accuracy: 0.9500\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.2362 - accuracy: 0.9249 - val_loss: 0.1315 - val_accuracy: 0.9700\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.2177 - accuracy: 0.9314 - val_loss: 0.1512 - val_accuracy: 0.9550\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.1965 - accuracy: 0.9369 - val_loss: 0.1341 - val_accuracy: 0.9550\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.1764 - accuracy: 0.9437 - val_loss: 0.1187 - val_accuracy: 0.9650\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.1722 - accuracy: 0.9437 - val_loss: 0.1224 - val_accuracy: 0.9700\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.1589 - accuracy: 0.9514 - val_loss: 0.1059 - val_accuracy: 0.9700\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.1362 - accuracy: 0.9554 - val_loss: 0.1051 - val_accuracy: 0.9700\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.1374 - accuracy: 0.9580 - val_loss: 0.0867 - val_accuracy: 0.9700\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.1266 - accuracy: 0.9563 - val_loss: 0.0830 - val_accuracy: 0.9750\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.1465 - accuracy: 0.9506 - val_loss: 0.0997 - val_accuracy: 0.9800\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.1212 - accuracy: 0.9637 - val_loss: 0.0890 - val_accuracy: 0.9800\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.1127 - accuracy: 0.9597 - val_loss: 0.0753 - val_accuracy: 0.9800\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.1019 - accuracy: 0.9660 - val_loss: 0.0889 - val_accuracy: 0.9800\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.1040 - accuracy: 0.9666 - val_loss: 0.0753 - val_accuracy: 0.9800\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.1004 - accuracy: 0.9649 - val_loss: 0.0816 - val_accuracy: 0.9750\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0910 - accuracy: 0.9743 - val_loss: 0.0776 - val_accuracy: 0.9800\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0835 - accuracy: 0.9723 - val_loss: 0.1065 - val_accuracy: 0.9700\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0788 - accuracy: 0.9763 - val_loss: 0.0723 - val_accuracy: 0.9750\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0747 - accuracy: 0.9746 - val_loss: 0.0836 - val_accuracy: 0.9800\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0724 - accuracy: 0.9737 - val_loss: 0.0950 - val_accuracy: 0.9650\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0683 - accuracy: 0.9780 - val_loss: 0.0831 - val_accuracy: 0.9800\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0688 - accuracy: 0.9769 - val_loss: 0.0887 - val_accuracy: 0.9750\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0612 - accuracy: 0.9826 - val_loss: 0.0790 - val_accuracy: 0.9800\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0635 - accuracy: 0.9777 - val_loss: 0.0784 - val_accuracy: 0.9800\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0513 - accuracy: 0.9849 - val_loss: 0.0955 - val_accuracy: 0.9800\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0546 - accuracy: 0.9834 - val_loss: 0.0918 - val_accuracy: 0.9800\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0519 - accuracy: 0.9829 - val_loss: 0.0830 - val_accuracy: 0.9800\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0435 - accuracy: 0.9880 - val_loss: 0.1018 - val_accuracy: 0.9750\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0429 - accuracy: 0.9849 - val_loss: 0.0837 - val_accuracy: 0.9750\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0522 - accuracy: 0.9797 - val_loss: 0.0884 - val_accuracy: 0.9750\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0676 - accuracy: 0.9769 - val_loss: 0.0950 - val_accuracy: 0.9800\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0564 - accuracy: 0.9800 - val_loss: 0.0766 - val_accuracy: 0.9800\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0446 - accuracy: 0.9860 - val_loss: 0.0840 - val_accuracy: 0.9800\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0361 - accuracy: 0.9886 - val_loss: 0.0903 - val_accuracy: 0.9850\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0374 - accuracy: 0.9871 - val_loss: 0.0880 - val_accuracy: 0.9800\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0402 - accuracy: 0.9860 - val_loss: 0.0798 - val_accuracy: 0.9800\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0381 - accuracy: 0.9880 - val_loss: 0.0887 - val_accuracy: 0.9750\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0406 - accuracy: 0.9871 - val_loss: 0.0804 - val_accuracy: 0.9800\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0337 - accuracy: 0.9889 - val_loss: 0.0896 - val_accuracy: 0.9700\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0315 - accuracy: 0.9889 - val_loss: 0.0590 - val_accuracy: 0.9850\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0307 - accuracy: 0.9894 - val_loss: 0.0794 - val_accuracy: 0.9750\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 0.0931 - val_accuracy: 0.9850\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0346 - accuracy: 0.9894 - val_loss: 0.0688 - val_accuracy: 0.9800\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 0.1118 - val_accuracy: 0.9800\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0405 - accuracy: 0.9851 - val_loss: 0.1059 - val_accuracy: 0.9700\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0359 - accuracy: 0.9869 - val_loss: 0.1111 - val_accuracy: 0.9600\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0266 - accuracy: 0.9891 - val_loss: 0.0858 - val_accuracy: 0.9800\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0261 - accuracy: 0.9914 - val_loss: 0.0863 - val_accuracy: 0.9850\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0268 - accuracy: 0.9917 - val_loss: 0.0886 - val_accuracy: 0.9800\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0296 - accuracy: 0.9886 - val_loss: 0.0705 - val_accuracy: 0.9850\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0302 - accuracy: 0.9889 - val_loss: 0.0773 - val_accuracy: 0.9850\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0265 - accuracy: 0.9923 - val_loss: 0.0937 - val_accuracy: 0.9850\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 0.0986 - val_accuracy: 0.9850\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0284 - accuracy: 0.9894 - val_loss: 0.0908 - val_accuracy: 0.9850\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0715 - val_accuracy: 0.9800\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.1001 - val_accuracy: 0.9850\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.0947 - val_accuracy: 0.9850\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0275 - accuracy: 0.9897 - val_loss: 0.1155 - val_accuracy: 0.9800\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0273 - accuracy: 0.9897 - val_loss: 0.1325 - val_accuracy: 0.9750\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0283 - accuracy: 0.9906 - val_loss: 0.1188 - val_accuracy: 0.9800\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0265 - accuracy: 0.9894 - val_loss: 0.0837 - val_accuracy: 0.9850\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0242 - accuracy: 0.9911 - val_loss: 0.1097 - val_accuracy: 0.9800\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 0.1179 - val_accuracy: 0.9800\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0951 - val_accuracy: 0.9850\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0221 - accuracy: 0.9920 - val_loss: 0.1218 - val_accuracy: 0.9750\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.1187 - val_accuracy: 0.9800\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0144 - accuracy: 0.9946 - val_loss: 0.1225 - val_accuracy: 0.9850\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 0.0862 - val_accuracy: 0.9800\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0299 - accuracy: 0.9906 - val_loss: 0.1142 - val_accuracy: 0.9850\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.1128 - val_accuracy: 0.9700\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0151 - accuracy: 0.9943 - val_loss: 0.1225 - val_accuracy: 0.9800\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0177 - accuracy: 0.9929 - val_loss: 0.1028 - val_accuracy: 0.9800\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.1189 - val_accuracy: 0.9850\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.1008 - val_accuracy: 0.9850\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0168 - accuracy: 0.9934 - val_loss: 0.1123 - val_accuracy: 0.9800\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0156 - accuracy: 0.9940 - val_loss: 0.1010 - val_accuracy: 0.9750\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 1s 66ms/step - loss: 0.0151 - accuracy: 0.9937 - val_loss: 0.1398 - val_accuracy: 0.9750\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 1s 64ms/step - loss: 0.0168 - accuracy: 0.9931 - val_loss: 0.1274 - val_accuracy: 0.9800\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0206 - accuracy: 0.9914 - val_loss: 0.0980 - val_accuracy: 0.9800\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.1032 - val_accuracy: 0.9850\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0148 - accuracy: 0.9946 - val_loss: 0.0767 - val_accuracy: 0.9800\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.1217 - val_accuracy: 0.9850\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.0830 - val_accuracy: 0.9800\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.1354 - val_accuracy: 0.9850\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 0.0148 - accuracy: 0.9940 - val_loss: 0.1237 - val_accuracy: 0.9850\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.1203 - val_accuracy: 0.9800\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0191 - accuracy: 0.9926 - val_loss: 0.1466 - val_accuracy: 0.9800\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0182 - accuracy: 0.9926 - val_loss: 0.1663 - val_accuracy: 0.9750\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0149 - accuracy: 0.9937 - val_loss: 0.0847 - val_accuracy: 0.9700\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.1169 - val_accuracy: 0.9800\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0135 - accuracy: 0.9971 - val_loss: 0.1421 - val_accuracy: 0.9800\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0132 - accuracy: 0.9971 - val_loss: 0.1490 - val_accuracy: 0.9750\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0151 - accuracy: 0.9943 - val_loss: 0.1001 - val_accuracy: 0.9800\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.1208 - val_accuracy: 0.9750\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0171 - accuracy: 0.9931 - val_loss: 0.1294 - val_accuracy: 0.9800\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.1361 - val_accuracy: 0.9750\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.1270 - val_accuracy: 0.9800\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.1482 - val_accuracy: 0.9800\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0113 - accuracy: 0.9957 - val_loss: 0.1335 - val_accuracy: 0.9800\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0164 - accuracy: 0.9934 - val_loss: 0.1819 - val_accuracy: 0.9800\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.1351 - val_accuracy: 0.9800\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0145 - accuracy: 0.9943 - val_loss: 0.1193 - val_accuracy: 0.9800\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.1360 - val_accuracy: 0.9850\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.1449 - val_accuracy: 0.9800\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.1216 - val_accuracy: 0.9850\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.1262 - val_accuracy: 0.9800\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 0.1151 - val_accuracy: 0.9800\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.1498 - val_accuracy: 0.9850\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.1489 - val_accuracy: 0.9850\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.1421 - val_accuracy: 0.9850\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.1519 - val_accuracy: 0.9850\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.1648 - val_accuracy: 0.9800\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.1004 - val_accuracy: 0.9750\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1328 - val_accuracy: 0.9850\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.1503 - val_accuracy: 0.9800\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.1153 - val_accuracy: 0.9850\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.1263 - val_accuracy: 0.9850\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.1426 - val_accuracy: 0.9850\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0092 - accuracy: 0.9960 - val_loss: 0.1045 - val_accuracy: 0.9800\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.1630 - val_accuracy: 0.9700\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.1676 - val_accuracy: 0.9800\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.1587 - val_accuracy: 0.9800\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0143 - accuracy: 0.9940 - val_loss: 0.1708 - val_accuracy: 0.9850\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.1109 - val_accuracy: 0.9800\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0098 - accuracy: 0.9960 - val_loss: 0.1169 - val_accuracy: 0.9850\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.1295 - val_accuracy: 0.9800\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.1268 - val_accuracy: 0.9850\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0105 - accuracy: 0.9957 - val_loss: 0.1518 - val_accuracy: 0.9750\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.1807 - val_accuracy: 0.9650\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 0.1547 - val_accuracy: 0.9750\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.2160 - val_accuracy: 0.9800\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.1729 - val_accuracy: 0.9850\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.1502 - val_accuracy: 0.9850\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.1378 - val_accuracy: 0.9850\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0105 - accuracy: 0.9960 - val_loss: 0.1561 - val_accuracy: 0.9800\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1742 - val_accuracy: 0.9850\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 0.1599 - val_accuracy: 0.9850\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.1305 - val_accuracy: 0.9850\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.1688 - val_accuracy: 0.9800\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0082 - accuracy: 0.9960 - val_loss: 0.1569 - val_accuracy: 0.9850\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1641 - val_accuracy: 0.9750\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0101 - accuracy: 0.9960 - val_loss: 0.1972 - val_accuracy: 0.9800\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.1810 - val_accuracy: 0.9850\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0081 - accuracy: 0.9969 - val_loss: 0.1514 - val_accuracy: 0.9850\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0077 - accuracy: 0.9966 - val_loss: 0.1591 - val_accuracy: 0.9850\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.1727 - val_accuracy: 0.9850\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.1745 - val_accuracy: 0.9850\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 0.0076 - accuracy: 0.9969 - val_loss: 0.1370 - val_accuracy: 0.9850\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0075 - accuracy: 0.9969 - val_loss: 0.2013 - val_accuracy: 0.9800\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0151 - accuracy: 0.9934 - val_loss: 0.1273 - val_accuracy: 0.9850\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.1535 - val_accuracy: 0.9850\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.1682 - val_accuracy: 0.9800\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.1980 - val_accuracy: 0.9850\n",
      "Epoch 163/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0072 - accuracy: 0.9971 - val_loss: 0.1860 - val_accuracy: 0.9850\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.1926 - val_accuracy: 0.9850\n",
      "Epoch 165/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1977 - val_accuracy: 0.9850\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.1812 - val_accuracy: 0.9850\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.1626 - val_accuracy: 0.9850\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.1544 - val_accuracy: 0.9850\n",
      "Epoch 169/200\n",
      "14/14 [==============================] - 1s 64ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 0.2036 - val_accuracy: 0.9700\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.1977 - val_accuracy: 0.9750\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0160 - accuracy: 0.9934 - val_loss: 0.1932 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0109 - accuracy: 0.9954 - val_loss: 0.1307 - val_accuracy: 0.9850\n",
      "Epoch 173/200\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 0.1430 - val_accuracy: 0.9850\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.0070 - accuracy: 0.9971 - val_loss: 0.1759 - val_accuracy: 0.9850\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0051 - accuracy: 0.9974 - val_loss: 0.1766 - val_accuracy: 0.9850\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1770 - val_accuracy: 0.9850\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0070 - accuracy: 0.9966 - val_loss: 0.1924 - val_accuracy: 0.9850\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0071 - accuracy: 0.9971 - val_loss: 0.1782 - val_accuracy: 0.9850\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.1940 - val_accuracy: 0.9850\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1938 - val_accuracy: 0.9850\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.2152 - val_accuracy: 0.9850\n",
      "Epoch 182/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0058 - accuracy: 0.9977 - val_loss: 0.2153 - val_accuracy: 0.9850\n",
      "Epoch 183/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.2291 - val_accuracy: 0.9800\n",
      "Epoch 184/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.1752 - val_accuracy: 0.9850\n",
      "Epoch 185/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.1950 - val_accuracy: 0.9850\n",
      "Epoch 186/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.2126 - val_accuracy: 0.9850\n",
      "Epoch 187/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0055 - accuracy: 0.9977 - val_loss: 0.1916 - val_accuracy: 0.9800\n",
      "Epoch 188/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0066 - accuracy: 0.9960 - val_loss: 0.2100 - val_accuracy: 0.9800\n",
      "Epoch 189/200\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.0076 - accuracy: 0.9969 - val_loss: 0.1671 - val_accuracy: 0.9800\n",
      "Epoch 190/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.1294 - val_accuracy: 0.9800\n",
      "Epoch 191/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1400 - val_accuracy: 0.9800\n",
      "Epoch 192/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 0.1580 - val_accuracy: 0.9850\n",
      "Epoch 193/200\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.1633 - val_accuracy: 0.9850\n",
      "Epoch 194/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.1756 - val_accuracy: 0.9850\n",
      "Epoch 195/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.1942 - val_accuracy: 0.9800\n",
      "Epoch 196/200\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 0.0038 - accuracy: 0.9980 - val_loss: 0.1756 - val_accuracy: 0.9850\n",
      "Epoch 197/200\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.1698 - val_accuracy: 0.9850\n",
      "Epoch 198/200\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.1756 - val_accuracy: 0.9850\n",
      "Epoch 199/200\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 0.0037 - accuracy: 0.9983 - val_loss: 0.1715 - val_accuracy: 0.9850\n",
      "Epoch 200/200\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.1729 - val_accuracy: 0.9850\n"
     ]
    }
   ],
   "source": [
    "# 1. Import libraries and modules\n",
    "%load_ext tensorboard\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import numpy as np\n",
    "from dataset import load_hoda\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "np.random.seed(123)  # for reproducibility\n",
    "\n",
    "\n",
    "# Load pre-shuffled HODA data into train and test sets\n",
    "x_train_original, y_train_original, x_test_original, y_test_original = load_hoda(\n",
    "                                                                        training_sample_size=3500,\n",
    "                                                                        test_sample_size=400,size=28)\n",
    "\n",
    "# Preprocess input data\n",
    "''' 3.1: input data in numpy array format'''\n",
    "x_train = np.array(x_train_original)\n",
    "x_test = np.array(x_test_original)\n",
    "'''3.2 normalize our data values to the range [0, 1]'''\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Reshape to original image shape (n x 784)  ==> (n x 28 x 28 x 1)\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "\n",
    "# 4. Preprocess class labels\n",
    "y_train = keras.utils.to_categorical(y_train_original, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test_original, num_classes=10)\n",
    "\n",
    "\n",
    "# test and validation set\n",
    "x_val = x_test[:200]\n",
    "x_test = x_test[200:]\n",
    "y_val = y_test[:200]\n",
    "y_test = y_test[200:]\n",
    "\n",
    "# 5. Define model architecture\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# 6. Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 7. Fit model on training data\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "history = model.fit(x_train, y_train,\n",
    "          epochs=200, batch_size=256, validation_data = (x_val, y_val), callbacks=[tensorboard])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-859c790206f74be3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-859c790206f74be3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\"> دوره مقدماتی یادگیری عمیق<br>علیرضا اخوان پور<br>پنج شنبه، ۱۸ بهمن ۱۳۹۷<br>\n",
    "</div>\n",
    "<a href=\"http://class.vision\">Class.Vision</a> - <a href=\"http://AkhavanPour.ir\">AkhavanPour.ir</a> - <a href=\"https://github.com/Alireza-Akhavan/\">GitHub</a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "nbpresent": {
   "slides": {
    "300ee14f-a043-486e-b274-7ff253907cd7": {
     "id": "300ee14f-a043-486e-b274-7ff253907cd7",
     "prev": "cb74e0bc-4513-4d13-b7f1-14c3078a7927",
     "regions": {
      "26dc3f39-a230-447c-af4c-f5e5b2fb7835": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c58440a5-3f8f-4f37-9c79-6bf766209406",
        "part": "whole"
       },
       "id": "26dc3f39-a230-447c-af4c-f5e5b2fb7835"
      }
     }
    },
    "878aa53a-1444-4100-8f50-7a408191c579": {
     "id": "878aa53a-1444-4100-8f50-7a408191c579",
     "prev": null,
     "regions": {
      "a6c6843a-5ea6-4fbc-b890-3b4b8ae475b3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "588ee1fa-64b5-453b-ade7-8e6b2515821c",
        "part": "whole"
       },
       "id": "a6c6843a-5ea6-4fbc-b890-3b4b8ae475b3"
      }
     }
    },
    "96ffe88e-7b50-43de-afdd-942e564f4e3e": {
     "id": "96ffe88e-7b50-43de-afdd-942e564f4e3e",
     "prev": "878aa53a-1444-4100-8f50-7a408191c579",
     "regions": {
      "b7e52e12-489a-468d-b10c-af2024fd2856": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "de829a92-1fb6-44ad-a2c6-fc1001e1f6e1",
        "part": "whole"
       },
       "id": "b7e52e12-489a-468d-b10c-af2024fd2856"
      }
     }
    },
    "cb74e0bc-4513-4d13-b7f1-14c3078a7927": {
     "id": "cb74e0bc-4513-4d13-b7f1-14c3078a7927",
     "prev": "96ffe88e-7b50-43de-afdd-942e564f4e3e",
     "regions": {
      "444878ee-68f3-4abb-acff-a7079b21e86d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "25f3f538-1ee8-4d98-a6bb-14cbeb7a702d",
        "part": "whole"
       },
       "id": "444878ee-68f3-4abb-acff-a7079b21e86d"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
